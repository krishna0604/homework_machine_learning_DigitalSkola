# -*- coding: utf-8 -*-
"""HOMEWORK MACHINE LEARNING

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z5QjH8REdJoxZQEhDLrxSxCpHBM_UOS9
"""

import time # menghitung waktu
import pickle # tipe data menyimpan model

import pandas as pd
import numpy as np

from sklearn.neighbors import KNeighborsClassifier # import lib KNN. untuk meberi tahu cara mesin belajar
from sklearn.model_selection import train_test_split # panggil algoritma untuk melatih mesin
from sklearn.metrics import accuracy_score # lalu lihat hasilnya ketika dilatih menggunakan KNN itu hasilnya seperti apa

data = pd.read_csv('https://raw.githubusercontent.com/krishna0604/homework_machine_learning_DigitalSkola/main/Prediction%20Insurance.csv')
data.head()

data.shape # punya 12 variance (njumlah kolom)

data['Region_Code'].unique() # isinya hanya kode wilayah

"""# Data Processing

## a.) Handle missing data
"""

# Handle missing data = data yang hilang
data.info()
data.isna().sum() # menjumlahkan semua data kosong

"""Report : tidak ada data yang hilang

## a.) Handle duplicated data
"""

# atau
print('Jumlah baris duplicate: ', data.duplicated().sum())

df = data.drop_duplicates()
df.shape

# atau
print('Jumlah baris duplicate: ', df.duplicated().sum())

"""Data yang tidak duplikat sudah disimpan dalam df dan menghapus 269 data yang duplikat

## b.) Handle Outliers

Cek data outliers pada kolom 'Age', 'Annual_Premium', dan 'Vintage' karena terdapat angka yang memungkinkan adanya outlier

### Age
"""

## Daily Time Spent on Site ##

Q1_NumWebPurchases = np.quantile(df['Age'], .25)
Q3_NumWebPurchases = np.quantile(df['Age'], .75)
IQR_NumWebPurchases = Q3_NumWebPurchases - Q1_NumWebPurchases
min_IQR_NumWebPurchases = Q1_NumWebPurchases - 1.5 * IQR_NumWebPurchases
max_IQR_NumWebPurchases = Q3_NumWebPurchases + 1.5 * IQR_NumWebPurchases
nilai_min_NumWebPurchases = np.min(df['Age'])
nilai_max_NumWebPurchases = np.max(df['Age'])

print('')
print('C. Mencari outlier dari kolom NumWebPurchases')
print('1. nilai Q1 dari NumWebPurchases =', Q1_NumWebPurchases)
print('2. nilai Q3 dari NumWebPurchases =', Q3_NumWebPurchases)
print('3. nilai IQR dari NumWebPurchases =', IQR_NumWebPurchases)
print('4. nilai min IQR NumWebPurchases =', min_IQR_NumWebPurchases)
print('5. nilai max IQR NumWebPurchases =', max_IQR_NumWebPurchases)
print('6. nilai min dari NumWebPurchases =', nilai_min_NumWebPurchases)
print('7. nilai max dari NumWebPurchases =', nilai_max_NumWebPurchases)

if (nilai_min_NumWebPurchases < min_IQR_NumWebPurchases):
    print('Ditemukan low outlier!')
else:
    print('Tidak ditemukan low outlier!')

if (nilai_max_NumWebPurchases > max_IQR_NumWebPurchases):
    print('Ditemukan high outlier!')
else:
    print('Tidak ditemukan high outlier!')

"""### Annual_Premium"""

## Daily Time Spent on Site ##

Q1_NumWebPurchases = np.quantile(df['Annual_Premium'], .25)
Q3_NumWebPurchases = np.quantile(df['Annual_Premium'], .75)
IQR_NumWebPurchases = Q3_NumWebPurchases - Q1_NumWebPurchases
min_IQR_NumWebPurchases = Q1_NumWebPurchases - 1.5 * IQR_NumWebPurchases
max_IQR_NumWebPurchases = Q3_NumWebPurchases + 1.5 * IQR_NumWebPurchases
nilai_min_NumWebPurchases = np.min(df['Annual_Premium'])
nilai_max_NumWebPurchases = np.max(df['Annual_Premium'])

print('')
print('C. Mencari outlier dari kolom NumWebPurchases')
print('1. nilai Q1 dari NumWebPurchases =', Q1_NumWebPurchases)
print('2. nilai Q3 dari NumWebPurchases =', Q3_NumWebPurchases)
print('3. nilai IQR dari NumWebPurchases =', IQR_NumWebPurchases)
print('4. nilai min IQR NumWebPurchases =', min_IQR_NumWebPurchases)
print('5. nilai max IQR NumWebPurchases =', max_IQR_NumWebPurchases)
print('6. nilai min dari NumWebPurchases =', nilai_min_NumWebPurchases)
print('7. nilai max dari NumWebPurchases =', nilai_max_NumWebPurchases)

if (nilai_min_NumWebPurchases < min_IQR_NumWebPurchases):
    print('Ditemukan low outlier!')
else:
    print('Tidak ditemukan low outlier!')

if (nilai_max_NumWebPurchases > max_IQR_NumWebPurchases):
    print('Ditemukan high outlier!')
else:
    print('Tidak ditemukan high outlier!')

"""### Vintage"""

## Daily Time Spent on Site ##

Q1_NumWebPurchases = np.quantile(df['Vintage'], .25)
Q3_NumWebPurchases = np.quantile(df['Vintage'], .75)
IQR_NumWebPurchases = Q3_NumWebPurchases - Q1_NumWebPurchases
min_IQR_NumWebPurchases = Q1_NumWebPurchases - 1.5 * IQR_NumWebPurchases
max_IQR_NumWebPurchases = Q3_NumWebPurchases + 1.5 * IQR_NumWebPurchases
nilai_min_NumWebPurchases = np.min(df['Vintage'])
nilai_max_NumWebPurchases = np.max(df['Vintage'])

print('')
print('C. Mencari outlier dari kolom NumWebPurchases')
print('1. nilai Q1 dari NumWebPurchases =', Q1_NumWebPurchases)
print('2. nilai Q3 dari NumWebPurchases =', Q3_NumWebPurchases)
print('3. nilai IQR dari NumWebPurchases =', IQR_NumWebPurchases)
print('4. nilai min IQR NumWebPurchases =', min_IQR_NumWebPurchases)
print('5. nilai max IQR NumWebPurchases =', max_IQR_NumWebPurchases)
print('6. nilai min dari NumWebPurchases =', nilai_min_NumWebPurchases)
print('7. nilai max dari NumWebPurchases =', nilai_max_NumWebPurchases)

if (nilai_min_NumWebPurchases < min_IQR_NumWebPurchases):
    print('Ditemukan low outlier!')
else:
    print('Tidak ditemukan low outlier!')

if (nilai_max_NumWebPurchases > max_IQR_NumWebPurchases):
    print('Ditemukan high outlier!')
else:
    print('Tidak ditemukan high outlier!')

"""Ditemukan high outlier pada kolom Annual_Premium, maka akan di handle"""

Q1 = df['Annual_Premium'].quantile(0.25)
Q3 = df['Annual_Premium'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
df = df[(df['Annual_Premium'] >= lower_bound) & (df['Annual_Premium'] <= upper_bound)]

"""### Label Encoding"""

# Mengetahui nilai unik pada masing-masing kolom
unique_values = {col: df[col].unique() for col in df.columns}

# Menampilkan hasil
for col, values in unique_values.items():
    print(f"Kolom '{col}' memiliki nilai unik: {values}")
    print(" ")
    print(" -------------- ")
    print(" ")

"""#### Vehicle_Age"""

# Encoding - Education (Tipe ordinal - punya urutan)
df.loc[(df.Vehicle_Age == "> 2 Years"),"Vehicle_Age"] = 2
df.loc[(df.Vehicle_Age == "1-2 Year") ,"Vehicle_Age"] = 1
df.loc[(df.Vehicle_Age == "< 1 Year"),"Vehicle_Age"] = 0
# Adjusting data type
df.Vehicle_Age = df.Vehicle_Age.astype(int)

df.info()

"""### Vehicle_Damage"""

# Encoding - Education (Tipe ordinal - punya urutan)
df.loc[(df.Vehicle_Damage == "Yes"),"Vehicle_Damage"] = 1
df.loc[(df.Vehicle_Damage == "No") ,"Vehicle_Damage"] = 0
# Adjusting data type
df.Vehicle_Damage = df.Vehicle_Damage.astype(int)

df.info()

"""### One Hot Encoding"""

df_after = pd.get_dummies(df['Region_Code'])

df_region = pd.get_dummies(data['Region_Code']) # gimana mesin bsabedain region, maka get dummies. get dummies itu membuat mesin akan membaca 28 itu apa, 3 itu apa, dll.
# ini One-Hot Encoding. bagaimana mesin ketika baca dia tahu pola dan harus dalam bentuk binary

df = data[['Gender', 'Age', 'Driving_License', 'Response']]#.merge(df_region, left_index=True, right_index=True )
df.head(1)

df.info()

"""# Data Modelling"""

# data modelling
X = df.drop('Response', axis=1)# variabel input
y = df['Response'] # variabel output

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

def eval_classification(model):
  y_pred = model.predict(X_test)
  y_pred_train = model.predict(X_train)
  y_pred_proba = model.predict_proba(X_test) # output berupa probabilitas
  y_pred_proba_train = model.predict_proba(X_train)

  print('Akurasi (test_set) : ', accuracy_score(y_test, y_pred))
  print('Precision (test_set) : ', precision_score(y_test, y_pred))
  print('Recall (test_set) : ', recall_score(y_test, y_pred))
  print('F1-score (test_set) : ', f1_score(y_test, y_pred))

  print('AUC (test_proba) :', roc_auc_score (y_test, y_pred_proba[:, 1]))
  print('AUC (train_proba) :', roc_auc_score(y_train, y_pred_proba_train[:, 1]))

def show_feature_importance(model):
    feat_importances = pd.Series(model.feature_importances_, index=X.columns)
    ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))
    ax.invert_yaxis()

    plt.xlabel('score')
    plt.ylabel('feature')
    plt.title('feature importance score')

def show_best_hyperparameter(model):
    print(model.best_estimator_.get_params())

"""## a.) Logistic Regression"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X_train, y_train)
eval_classification(lr)

"""### result

- AUC ROC score gap : 0.0004
- Accuration : 0.876

### pickle
"""

# Menyimpan model ke dalam file pickle
with open('model_Logistic_Regression.pkl', 'wb') as file:
    pickle.dump(lr, file)

import os

# Nama file pickle yang telah disimpan
file_name = 'model_Logistic_Regression.pkl'

# Mendapatkan direktori kerja saat ini
current_directory = os.getcwd()

# Mendapatkan path lengkap file
file_path = os.path.join(current_directory, file_name)

# Cek apakah file ada dan tampilkan lokasi file
if os.path.exists(file_path):
    print(f"File '{file_name}' ditemukan di lokasi: {file_path}")
else:
    print(f"File '{file_name}' tidak ditemukan di direktori: {current_directory}")

# Tampilkan path lengkap file
print("Path lengkap file:", file_path)

from google.colab import files

# Download file pickle dari Google Colab
files.download('/content/model_Logistic_Regression.pkl')

"""## b.) Decision Tree"""

# decision tree
from sklearn.tree import DecisionTreeClassifier # import decision tree dari sklearn
dt = DecisionTreeClassifier() # inisiasi object dengan nama dt
dt.fit(X_train, y_train) # fit model decision tree dari data train
print("Model Evaluation (Decision Tree)")
eval_classification(dt)

"""### result

- AUC ROC score gap : 0.006
- Accuration : 0.876

### pickle
"""

# Menyimpan model ke dalam file pickle
with open('model_Decision_Tree.pkl', 'wb') as file:
    pickle.dump(dt, file)

import os

# Nama file pickle yang telah disimpan
file_name = 'model_Decision_Tree.pkl'

# Mendapatkan direktori kerja saat ini
current_directory = os.getcwd()

# Mendapatkan path lengkap file
file_path = os.path.join(current_directory, file_name)

# Cek apakah file ada dan tampilkan lokasi file
if os.path.exists(file_path):
    print(f"File '{file_name}' ditemukan di lokasi: {file_path}")
else:
    print(f"File '{file_name}' tidak ditemukan di direktori: {current_directory}")

# Tampilkan path lengkap file
print("Path lengkap file:", file_path)

from google.colab import files

# Download file pickle dari Google Colab
files.download('/content/model_Decision_Tree.pkl')

show_feature_importance(dt)

"""## c.) Random Forest"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
print('Model Evaluation (Random Forest)')
eval_classification(rf)

"""### result

- AUC ROC score gap : 0.006
- Accuration : 0.876

### pickle
"""

# Menyimpan model ke dalam file pickle
with open('model_Random_Forest.pkl', 'wb') as file:
    pickle.dump(rf, file)

import os

# Nama file pickle yang telah disimpan
file_name = 'model_Random_Forest.pkl'

# Mendapatkan direktori kerja saat ini
current_directory = os.getcwd()

# Mendapatkan path lengkap file
file_path = os.path.join(current_directory, file_name)

# Cek apakah file ada dan tampilkan lokasi file
if os.path.exists(file_path):
    print(f"File '{file_name}' ditemukan di lokasi: {file_path}")
else:
    print(f"File '{file_name}' tidak ditemukan di direktori: {current_directory}")

# Tampilkan path lengkap file
print("Path lengkap file:", file_path)

from google.colab import files

# Download file pickle dari Google Colab
files.download('/content/model_Random_Forest.pkl')

show_feature_importance(rf)

"""## d.) KNN"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
print('Model Evaluation (KNN)')
eval_classification(knn)

"""### result

- AUC ROC score gap : 0.005
- Accuration : 0.857

### pickle
"""

# Menyimpan model ke dalam file pickle
with open('model_KNN.pkl', 'wb') as file:
    pickle.dump(knn, file)

import os

# Nama file pickle yang telah disimpan
file_name = 'model_KNN.pkl'

# Mendapatkan direktori kerja saat ini
current_directory = os.getcwd()

# Mendapatkan path lengkap file
file_path = os.path.join(current_directory, file_name)

# Cek apakah file ada dan tampilkan lokasi file
if os.path.exists(file_path):
    print(f"File '{file_name}' ditemukan di lokasi: {file_path}")
else:
    print(f"File '{file_name}' tidak ditemukan di direktori: {current_directory}")

# Tampilkan path lengkap file
print("Path lengkap file:", file_path)

from google.colab import files

# Download file pickle dari Google Colab
files.download('/content/model_KNN.pkl')

"""## e.) Naive Bayes"""

# Applying Naive Bayes
from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_train, y_train)
print('Model Evaluation (Naive Bayes)')
eval_classification(gnb)

"""### result

- AUC ROC score gap : 0.01
- Accuration : 0.876

### pickle
"""

# Menyimpan model ke dalam file pickle
with open('model_Naive_Bayes.pkl', 'wb') as file:
    pickle.dump(gnb, file)

import os

# Nama file pickle yang telah disimpan
file_name = 'model_Naive_Bayes.pkl'

# Mendapatkan direktori kerja saat ini
current_directory = os.getcwd()

# Mendapatkan path lengkap file
file_path = os.path.join(current_directory, file_name)

# Cek apakah file ada dan tampilkan lokasi file
if os.path.exists(file_path):
    print(f"File '{file_name}' ditemukan di lokasi: {file_path}")
else:
    print(f"File '{file_name}' tidak ditemukan di direktori: {current_directory}")

# Tampilkan path lengkap file
print("Path lengkap file:", file_path)

from google.colab import files

# Download file pickle dari Google Colab
files.download('/content/model_Naive_Bayes.pkl')

"""## f.) XGBoost"""

from xgboost import XGBClassifier

xg = XGBClassifier()
xg.fit(X_train, y_train)
print('Model Evaluation (XGBoost)')
eval_classification(xg)

"""### result

- AUC ROC score gap : 0.006
- Accuration : 0.876

### pickle
"""

# Menyimpan model ke dalam file pickle
with open('model_XGBoost.pkl', 'wb') as file:
    pickle.dump(xg, file)

import os

# Nama file pickle yang telah disimpan
file_name = 'model_XGBoost.pkl'

# Mendapatkan direktori kerja saat ini
current_directory = os.getcwd()

# Mendapatkan path lengkap file
file_path = os.path.join(current_directory, file_name)

# Cek apakah file ada dan tampilkan lokasi file
if os.path.exists(file_path):
    print(f"File '{file_name}' ditemukan di lokasi: {file_path}")
else:
    print(f"File '{file_name}' tidak ditemukan di direktori: {current_directory}")

# Tampilkan path lengkap file
print("Path lengkap file:", file_path)

from google.colab import files

# Download file pickle dari Google Colab
files.download('/content/model_XGBoost.pkl')

"""## g.) AdaBoost"""

from sklearn.ensemble import AdaBoostClassifier
clf = AdaBoostClassifier()
clf.fit(X_train, y_train)
print('Model Evaluation (Adaboost)')
eval_classification(clf)

"""### result

- AUC ROC score gap : 0.0001
- Accuration : 0.876

### pickle
"""

# Menyimpan model ke dalam file pickle
with open('model_AdaBoost.pkl', 'wb') as file:
    pickle.dump(clf, file)

import os

# Nama file pickle yang telah disimpan
file_name = 'model_AdaBoost.pkl'

# Mendapatkan direktori kerja saat ini
current_directory = os.getcwd()

# Mendapatkan path lengkap file
file_path = os.path.join(current_directory, file_name)

# Cek apakah file ada dan tampilkan lokasi file
if os.path.exists(file_path):
    print(f"File '{file_name}' ditemukan di lokasi: {file_path}")
else:
    print(f"File '{file_name}' tidak ditemukan di direktori: {current_directory}")

# Tampilkan path lengkap file
print("Path lengkap file:", file_path)

from google.colab import files

# Download file pickle dari Google Colab
files.download('/content/model_XGBoost.pkl')